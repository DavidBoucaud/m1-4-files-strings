{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Workshop Python Intro.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyPMuPsz+efoYpJzg8ElS0Ut"},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{},"source":["# Safe dict reading\n","\n","define a function `safe_dict(d, k)` that takes in a python dict `d` and a key `k` and makes it safe to read even with keys that aren't in the dictionary. If you try to read from the dictionary with a bad key, it should return 0 instead.\n","\n","```\n","d = {1 : 2, 3 : 4}\n","safe_dict(d, 1) -> 2\n","safe_dict(d, 'cat') -> 0\n","```"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["def safe_dict(x, y):\n","    if y in x:\n","        return x[y]\n","    else:\n","        return 0\n","\n","d = {1 : 2, 3 : 4}\n","\n","print(safe_dict(d, 1))\n","print(safe_dict(d, 'cat'))\n","    "]},{"cell_type":"markdown","metadata":{"colab":{},"colab_type":"code","id":"tl_ZhkbEtiTD"},"source":["# File Reading: Hamlet Exercises\n","\n","Open `hamlet.txt` in the `data` folder\n","\n","### 1. Mentionned Hamlet\n","\n","How many times is hamlet mentioned in the book?\n","\n","Use python and line iteration to count it up"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["with open('data\\hamlet.txt') as f:\n","    contents = f.read()\n","    count = contents.count(\"HAMLET\") + contents.count(\"Hamlet\")\n","\n","print(count)"]},{"cell_type":"markdown","metadata":{},"source":["### 2. File Reading as a .py program\n","\n","Make a python file that defines a function that counts the number of times hamlet is mentionned using the code in the previous exercise.\n","\n","Then import it in your notebook and call it here."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["text =  open('ProgramText.txt', 'w')\n","\n","text.write(\"\"\"\n","    with open('data\\hamlet.txt') as f:\n","    contents = f.read()\n","    count = contents.count(\"HAMLET\") + contents.count(\"Hamlet\")\n","\n","print(count)\n","    \"\"\")\n","text.close\n","\n","text = open('ProgramText.txt', 'r')\n","out = text.read()\n","text.close()\n","\n","print(out)\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### 3. Unique words in hamlet\n","\n","Write a program that counts the unique words in hamlet."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["print(len(set(word for word in open('data\\hamlet.txt', 'r').read().split())))"]},{"cell_type":"markdown","metadata":{},"source":["# File Reading 2: A Python library.\n","\n","In the `data` folder, you will find a folder called `csrgraph` which is a python library.\n","\n","### 1. File count\n","\n","Count the `py` files in the library using the `os` package"]},{"cell_type":"code","execution_count":37,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["8"]},"metadata":{},"execution_count":37}],"source":["import os\n","\n","len(os.listdir('data\\csrgraph'))"]},{"cell_type":"markdown","metadata":{},"source":["### 2. For the following packages, count the number of files that import them:\n","\n","- pandas \n","\n","- numpy\n","\n","- numba"]},{"cell_type":"code","execution_count":74,"metadata":{},"outputs":[{"output_type":"stream","name":"stdout","text":["pandas 4\nnumpy 6\nnumba 6\n"]}],"source":["import os\n","\n","packages = ['pandas', 'numpy', 'numba']\n","for package in packages:\n","    count = 0\n","    for filename in os.listdir('data\\csrgraph'):\n","        with open(os.path.join('data\\csrgraph', filename), 'r') as file:\n","            for line in file.readlines():\n","                if package in line:\n","                    count += 1\n","                    break\n","    print(package, count)"]},{"cell_type":"markdown","metadata":{},"source":["# First NLP Program: IDF\n","\n","Given a list of words, the the inverse document frequency (IDF) is a basic statistic of the amount of information of each word in the text.\n","\n","The IDF formulat is:\n","\n","$$IDF(w) = ln(\\dfrac{N}{1 + n(w)})$$\n","\n","Where:\n","\n","- $w$ is the token (unique word),\n","- $n(w)$ is the number of documents that $w$ occurs in,\n","- $N$ is the total number of documents\n","\n","Write a function, `idf(docs)` that takes in a list of lists of words and returns a dictionary  `word -> idf score`\n","\n","Example:\n","\n","```\n","IDF([['interview', 'questions'], ['interview', 'answers']]) -> {'questions': 0.0, \n","                                                                'interview': -0.4, \n","                                                                'answers': 0.0}\n","\n","\n","```"]},{"cell_type":"code","execution_count":123,"metadata":{},"outputs":[{"output_type":"execute_result","data":{"text/plain":["{'interview': -0.40546510810816444, 'questions': 0.0, 'answers': 0.0}"]},"metadata":{},"execution_count":123}],"source":["import numpy as np\n","\n","def idf(docs):\n","    N = len(docs)\n","    results = {}\n","    words = []\n","    for i in docs:\n","        for j in i:\n","            words.append(j)\n","    result = set(words)\n","\n","    for i in words:\n","        nw = 0\n","        for j in docs:\n","            if i in j:\n","                nw +=1\n","\n","        results[i] = np.log(N/(1+nw))\n","        \n","    return(results)\n","\n","\n","idf([['interview', 'questions'], ['interview', 'answers']])"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import numpy as np\n","\n","def idf(docs):\n","    d = set(docs[0]+ docs[1])\n","    result = {}\n","    N = len(docs)\n","    nw = 0\n","    \n","    for w in d:\n","        if w in docs[0]:\n","            nw =+ 1\n","        if w in docs[1]:\n","            nw =+ 1\n","        result[w] = np.log(N/(1+nw))\n","    return result\n","\n","\n","idf([['interview', 'questions'], ['interview', 'answers']])"]},{"cell_type":"markdown","metadata":{"colab":{},"colab_type":"code","id":"82bfnc_KueoX"},"source":["# Stretch Goal: TF-IDF on Hamlet\n","\n","The TF-IDF score is a commonly used statistic for the importance of words. Its $\\frac{TF}{IDF}$ where TF is the \"term frequency\" (eg. how often the words happens in the document).\n","\n","Calculate the TF-IDF dictionary on the Hamlet book.\n","\n","What's the TF-IDF of \"Hamlet\"?\n","\n","What's the word with the highest TF-IDF in the book?"]},{"cell_type":"markdown","metadata":{},"source":["# Stretch Goal: Speaker count\n","\n","Use a regular expression and looping over the `hamlet.txt` file to build a dictionary `character_name -> # times speaking`.\n","\n","Who speaks the most often? Who speaks the least often?"]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":[]}]}